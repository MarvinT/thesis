\chapter{Discussion}
more elaboration on paper results
a new possible direction for research into \CP and secondary 
better generative models coming out all the time

could also apply thielk curve to exploration of artificial neural network representations 

This thesis represents my attempts to apply machine learning and develop techniques to handle high dimensional temporal data in Neuroscience. As neuroscientific data aquisition techniques have advanced, we now record more data than was previously imaginable. Our attempts to interpret these data in some way parallel the evolutionary forces that drove the brain to process and interpret the many high dimensional sensory signals it receives. 

autoencoder styled unsupervised techniques -- information bottleneck
nonlinear dimensionality reduction. disentangling.

information theory -> predictive information

not throwing out temporal information
these methods will prove useful in the analysis of neuro data
ICA, DDA, CPC
sugihara embedding

themes:
don't throw out temporal information
don't assume normal distribution
don't assume linear scaling

k-s statistic
topological data analysis
distributions
distances
How spaces are related