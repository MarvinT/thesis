This thesis represents my attempts to apply machine learning and develop techniques to handle high dimensional temporal data in Neuroscience. As neuroscientific data aquisition techniques have advanced, we now record more data than was previously imaginable. Our attempts to interpret these data in some way parallel the evolutionary forces that drove the brain to process and interpret the many high dimensional sensory signals it receives. 

autoencoder styled unsupervised techniques -- information bottleneck
nonlinear dimensionality reduction. disentangling.

information theory -> predictive information
A video of two people talking in a living room with a tv displaying static - most of the Shannon information in the video will be in the tv's display. and while it may be a result of a particle left by the big bang hitting the antenna, our brain doesn't devote the majority of its resources to keep track of the white noise patterns. i.e. the brain's sensory processing system isn't designed to maximize the mutual information between the sensory signals it receives. Instead, if you consider the temporal information, the brain tries to encode the predictive information within its sensory streams. 

not throwing out temporal information
these methods will prove useful in the analysis of neuro data
ICA, DDA, CPC
sugihara embedding

themes:
don't throw out temporal information
don't assume normal distribution
don't assume linear scaling

k-s statistic
topological data analysis
distributions
distances
How spaces are related